
# ğŸ“¦ iFood Case â€” AnÃ¡lise de Campanha com Cupons

Este projeto realiza uma **anÃ¡lise completa de uma campanha de cupons no iFood**, combinando **teste A/B**, **estatÃ­stica aplicada**, **anÃ¡lise financeira (ROI e LTV)** e **segmentaÃ§Ã£o de usuÃ¡rios** para avaliar o impacto da aÃ§Ã£o em mÃ©tricas comportamentais e de negÃ³cio.

A anÃ¡lise foi desenvolvida utilizando **PySpark**, bibliotecas estatÃ­sticas em Python e tÃ©cnicas de Machine Learning para suportar decisÃµes orientadas a dados.

---

## ğŸ§© Contexto do Problema

No iFood, diferentes Ã¡reas utilizam testes A/B para validar hipÃ³teses de crescimento e avaliar o impacto de novas iniciativas.  
Neste case, foi fornecida uma base de pedidos contendo uma **marcaÃ§Ã£o de usuÃ¡rios em grupo controle e grupo target**, onde o grupo target recebeu um **cupom promocional**.

Os objetivos principais foram:

1. Avaliar se a campanha teve **impacto significativo**;
2. Analisar a **viabilidade financeira** da iniciativa;
3. Criar **segmentaÃ§Ãµes de clientes** relevantes para o teste;
4. Propor **melhorias e prÃ³ximos passos**.

---

## ğŸ“‹ Premissas

- O **iFood financiou 100% do valor do cupom**;
- O valor do cupom **nÃ£o estÃ¡ refletido diretamente no valor do pedido** â€” a coluna `discount` encontra-se zerada na base original;
- O objetivo da campanha **nÃ£o Ã© lucro imediato**, mas sim **aumentar retenÃ§Ã£o e LTV** no mÃ©dio e longo prazo;
- A **margem de contribuiÃ§Ã£o** adotada na anÃ¡lise Ã© de **25%**.

---

## ğŸ› ï¸ Etapas do Projeto

### 1ï¸âƒ£ PreparaÃ§Ã£o e Limpeza dos Dados
- ValidaÃ§Ã£o de schema e tipos de dados;
- CorreÃ§Ã£o de formataÃ§Ãµes conforme documentaÃ§Ã£o;
- Garantia de consistÃªncia no nÃºmero de registros;
- Tratamento de valores nulos;
- CriaÃ§Ã£o de chaves auxiliares;
- PreparaÃ§Ã£o da base analÃ­tica por cliente (`customer_id`).

---

### 2ï¸âƒ£ AnÃ¡lise ExploratÃ³ria (EDA)
Foram analisadas distribuiÃ§Ãµes, estatÃ­sticas descritivas e outliers das principais variÃ¡veis numÃ©ricas, como:
- Valor total do pedido;
- FrequÃªncia de compra;
- Ticket mÃ©dio;
- RecÃªncia;
- Valor total gasto.

#### Tratamento de Outliers
Foram testados dois mÃ©todos:
- Corte por percentil (P99);
- MÃ©todo do Intervalo Interquartil (IQR).

O **IQR** foi escolhido por ser mais robusto para distribuiÃ§Ãµes assimÃ©tricas e preservar melhor o comportamento central dos dados.

---

### 3ï¸âƒ£ ConstruÃ§Ã£o da Base AnalÃ­tica Final
Foi criada uma base agregada por **customer_id**, contendo, por exemplo:
- Quantidade de pedidos;
- FrequÃªncia mensal;
- Ticket mÃ©dio;
- Valor total gasto;
- RecÃªncia (mediana do tempo entre pedidos).

Essa base foi utilizada tanto no teste A/B quanto na segmentaÃ§Ã£o.

---

## ğŸ§ª Teste A/B â€” MÃ©tricas Avaliadas

As mÃ©tricas foram comparadas entre **grupo controle** e **grupo target**, com testes estatÃ­sticos adequados:

- **RetenÃ§Ã£o** â†’ teste de proporÃ§Ãµes (z-test);
- **FrequÃªncia de pedidos** â†’ teste Mann-Whitney / t-test;
- **Ticket mÃ©dio** â†’ t-test;
- **RecÃªncia (tempo entre pedidos)** â†’ Mann-Whitney;
- **Valor total gasto por cliente** â†’ t-test.

### ğŸ“ˆ Principais Resultados

- **RetenÃ§Ã£o**: aumento estatisticamente significativo no grupo target;
- **FrequÃªncia**: aumento significativo no nÃºmero de pedidos;
- **Ticket mÃ©dio**: sem diferenÃ§a estatisticamente significativa;
- **RecÃªncia**: reduÃ§Ã£o do tempo entre pedidos no grupo target;
- **Valor total gasto**: uplift significativo no grupo target.

ğŸ‘‰ A campanha alterou o **comportamento de compra**, e nÃ£o o preÃ§o mÃ©dio.

---

## ğŸ’° AnÃ¡lise de Viabilidade Financeira

### Premissas Financeiras
- Custo do cupom: **R$ 10,00 por usuÃ¡rio**;
- Margem de contribuiÃ§Ã£o: **25%**;
- AnÃ¡lise separada em **curto prazo (perÃ­odo do teste)** e **longo prazo (LTV)**.
---

## ğŸ§  SegmentaÃ§Ã£o de UsuÃ¡rios

Foi aplicada segmentaÃ§Ã£o via **KMeans**, utilizando variÃ¡veis comportamentais e financeiras.

### DefiniÃ§Ã£o do nÃºmero de clusters
- MÃ©todo do cotovelo (Elbow Method);
- Ãndice de Calinski-Harabasz.

ğŸ“Œ O valor **k = 3** foi escolhido por apresentar o melhor equilÃ­brio entre separaÃ§Ã£o estatÃ­stica e interpretabilidade de negÃ³cio.

---

### ğŸ’» Execute no Google Colab

VocÃª pode executar este projeto diretamente no Google Colab, sem necessidade de configuraÃ§Ã£o local.

ğŸ‘‰ [Abrir no Google Colab!](https://colab.research.google.com/drive/1AoaEq6VbSvaBpX3oBeWwLl-npcQiZC3i?usp=sharing)

---

## âš™ï¸ Requisitos

Para executar o notebook, Ã© necessÃ¡rio:

- Python â‰¥ 3.8  
- Apache Spark (via `pyspark`)  

### Bibliotecas Python
```bash
from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql.window import Window
from pyspark.sql.functions import col, sum as spark_sum, least, when
from pyspark.sql.functions import (
    min as spark_min, max as spark_max, col, sum, avg, countDistinct, lit,
    from_json, explode, datediff, current_date, expr, mean,
    percentile_approx, count, isnan, when
)
from pyspark.sql.window import Window
from pyspark.sql.functions import (
    col, count, countDistinct, avg, sum as spark_sum,
    min, max, datediff, round as spark_round, first
)
from pyspark.sql.types import (
    DoubleType, IntegerType, StringType, StructType,
    StructField, ArrayType, BooleanType, LongType, FloatType
)
from pyspark.ml.feature import StringIndexer
from pyspark.ml.evaluation import ClusteringEvaluator
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import os
import tarfile
import gzip
import shutil
import builtins
from sklearn.preprocessing import StandardScaler
from statsmodels.stats.proportion import proportions_ztest
from scipy.stats import ttest_ind, mannwhitneyu
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn.metrics import calinski_harabasz_score


